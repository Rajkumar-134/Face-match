{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a06b7c65",
   "metadata": {},
   "source": [
    "# ðŸ’» InsightFace Matcher - Jupyter Notebook Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a9243b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import insightface\n",
    "from insightface.app import FaceAnalysis\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class InsightFaceMatcher:\n",
    "    def __init__(self, det_size=(640, 640), threshold=0.4):\n",
    "        self.app = FaceAnalysis(name='buffalo_l', providers=['CPUExecutionProvider'])\n",
    "        self.app.prepare(ctx_id=0, det_size=det_size)\n",
    "        self.threshold = threshold\n",
    "        logger.info(\"InsightFace matcher initialized successfully\")\n",
    "\n",
    "    def preprocess_image(self, img):\n",
    "        \"\"\"Preprocess image for better face detection\"\"\"\n",
    "        # Convert grayscale to 3-channel RGB\n",
    "        if len(img.shape) == 2:\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            logger.info(\"Converted grayscale image to RGB.\")\n",
    "        elif len(img.shape) == 3 and img.shape[2] == 1:\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "            logger.info(\"Converted single-channel image to RGB.\")\n",
    "        elif len(img.shape) == 3 and img.shape[2] == 3:\n",
    "            # Convert BGR to RGB\n",
    "            img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        else:\n",
    "            img_rgb = img\n",
    "\n",
    "        # Histogram equalization for each channel (improves contrast)\n",
    "        img_yuv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2YUV)\n",
    "        img_yuv[:, :, 0] = cv2.equalizeHist(img_yuv[:, :, 0])\n",
    "        img_eq = cv2.cvtColor(img_yuv, cv2.COLOR_YUV2RGB)\n",
    "        logger.info(\"Applied histogram equalization.\")\n",
    "\n",
    "        # Upscale small images to at least 512x512 (increased from 256x256)\n",
    "        h, w = img_eq.shape[:2]\n",
    "        if h < 512 or w < 512:\n",
    "            scale = max(512 / h, 512 / w)\n",
    "            new_size = (int(w * scale), int(h * scale))\n",
    "            # Use INTER_LANCZOS4 for better quality upscaling of small images\n",
    "            img_eq = cv2.resize(img_eq, new_size, interpolation=cv2.INTER_LANCZOS4)\n",
    "            logger.info(f\"Upscaled image from {w}x{h} to {img_eq.shape[1]}x{img_eq.shape[0]} (scale: {scale:.2f}x).\")\n",
    "\n",
    "        # Ensure image is in uint8 format\n",
    "        if img_eq.dtype != np.uint8:\n",
    "            img_eq = (img_eq * 255).astype(np.uint8)\n",
    "\n",
    "        return img_eq\n",
    "\n",
    "    def get_embedding(self, img):\n",
    "        \"\"\"Get face embedding with multiple detection attempts\"\"\"\n",
    "        # Preprocess image\n",
    "        img_processed = self.preprocess_image(img)\n",
    "        \n",
    "        # Try different detection sizes for better face detection\n",
    "        detection_sizes = [(640, 640), (320, 320), (1280, 1280), (1600, 1600)]\n",
    "        \n",
    "        # For very small images, try even larger detection sizes\n",
    "        h, w = img_processed.shape[:2]\n",
    "        if h < 200 or w < 200:\n",
    "            detection_sizes.extend([(2000, 2000), (2400, 2400)])\n",
    "            logger.info(f\"Image is very small ({w}x{h}), adding larger detection sizes.\")\n",
    "        \n",
    "        for det_size in detection_sizes:\n",
    "            try:\n",
    "                # Temporarily change detection size\n",
    "                self.app.det_model.det_size = det_size\n",
    "                \n",
    "                # Get faces\n",
    "                faces = self.app.get(img_processed)\n",
    "                logger.info(f\"Detection attempt with size {det_size}: Found {len(faces)} faces\")\n",
    "                \n",
    "                if faces:\n",
    "                    # Return the first face embedding\n",
    "                    embedding = faces[0].embedding\n",
    "                    logger.info(f\"Successfully extracted face embedding with size {det_size}\")\n",
    "                    return embedding\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"Detection failed with size {det_size}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # If no faces found with any size, try with original image\n",
    "        try:\n",
    "            faces = self.app.get(img_processed)\n",
    "            logger.info(f\"Final attempt: Found {len(faces)} faces\")\n",
    "            if faces:\n",
    "                return faces[0].embedding\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Final detection attempt failed: {e}\")\n",
    "        \n",
    "        logger.error(\"No faces detected in image after all attempts\")\n",
    "        return None\n",
    "\n",
    "    def compare(self, img1, img2):\n",
    "        \"\"\"Compare two images and return similarity result\"\"\"\n",
    "        logger.info(\"Starting face comparison...\")\n",
    "        \n",
    "        # Get embeddings for both images\n",
    "        emb1 = self.get_embedding(img1)\n",
    "        emb2 = self.get_embedding(img2)\n",
    "        \n",
    "        if emb1 is None:\n",
    "            logger.error(\"No face detected in first image\")\n",
    "            return \"No face detected in image 1\", 0.0\n",
    "        elif emb2 is None:\n",
    "            logger.error(\"No face detected in second image\")\n",
    "            return \"No face detected in image 2\", 0.0\n",
    "        \n",
    "        # Calculate similarity\n",
    "        try:\n",
    "            sim = np.dot(emb1, emb2) / (np.linalg.norm(emb1) * np.linalg.norm(emb2))\n",
    "            logger.info(f\"Similarity score: {sim:.4f}\")\n",
    "            \n",
    "            result = \"Same Person\" if sim > self.threshold else \"Different Person\"\n",
    "            return result, float(sim)\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error calculating similarity: {e}\")\n",
    "            return \"Error calculating similarity\", 0.0\n",
    "\n",
    "# Required dependencies:\n",
    "# pip install insightface onnxruntime opencv-python"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
